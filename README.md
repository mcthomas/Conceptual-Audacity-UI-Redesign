# Conceptual-Audacity-UI-Redesign
A conceptual UI overhaul and redesign for Audacity, to demonstrate principles in UX &amp; UI design for human-computer interaction.

## Audacity Redesign Analysis
   Devising scenarios for evaluating the most critical deficiencies within Audacity was not easy, especially through the medium of direct observation with minimal intervention. The goal was approached with the intent of evaluating user comfort with panel tools, effects dropdowns, and mouse-click movements within the workspace pane. Covering all this ground was best accomplished with tasking as simply as possible. This helps to isolate the most common trouble points through repeated behaviors and patterns amongst all three participants of our three contextual inquiries. With the video recordings and careful notes, the hope was to identify these trouble points and begin assessing the most intuitive remedies with respect to user interface missteps and functional locality across the span of submenus and keybindings. Reflecting on these findings should enable us to adopt the most effective redesign approach and subsequent strategies for later product improvement to improve human interactions and the overall experience with Audacity.
   
   Given that Audacity is a digital audio workstation, there had to be real time audio recorded of some sort for manipulation by the user. We settled on vocal recordings of spoken words to keep samples consistent and to ensure the input edits can be easily cross-compared with respect to user interaction. Before initiating these recordings, the participant must frequently create new projects, new tracks, and new recordings. The idea was to see if even the most rudimentary tasks were accomplished identically every time, or differently for ease of use between all three inquiries. Any hesitation with these tasks, or attempts to accomplish them with separate keybindings or context menus, had to be observed for indications of unintuitive design at even the most basic level. As the user began to record their voice, it was carefully observed as to whether there was a lack of assurance regarding the input source, as well as knowledge of the audio actually being captured. Luckily the default setting was already bound to the internal mic and the track preview had a decibel graph. However, seeing the subsequent assurance experienced after the recording was notable for indicating a potential need for stronger visual indicators of the current recording configuration. Beyond this most basic tasking, trimming audio tracks was a frequent function required of the user. This was especially notable in seeing how users deliberated between actually using the trim tool control as apposed to making incremental selections and deleting them with menubar controls or keybindings. The breakdown between user tendency and hesitation in this respect was significant. The presentation of the workspace as the largest pane view seemed to encourage a visual approach to editing. It was for this reason that we believe users found it more favorable and intuitive to drag selections in the timeline rather than seek out the trim tool in the toolbar. Other tasks, such as renaming or deleting individual tracks entirely, was fairly easy for the users since these options could be identified and changed directly on the track header sidebar. With respect to effects, we chose to assess menubar navigation and the associated context panes by asking the user to change track portions’ pitches and speeds. Applying the effects didn’t initially seem well understood to the users with respect to their permanence or their expected prevalence in the track, based solely on just the numeric fields and dropdown options allotted before applying. This resulted in a few attempts and undos before they were satisfied with their approach to the task. Moreover, undo was used (both from the “edit” menubar option and the keybinding) heavily as a band-aid for frequent mouse-clicks and for reapplying effects. This was a very common indicator of accidental errors such as collapsing the track preview, applying an effect with inaccurate parameters, zooming too far in one direction, etc. On the topic of the zoom tool, it was a parallel occurrence. The user easily zoomed in too far and had to either pan back to the desired portion of the timeline for cutting or effects, or undo their action. This was made more difficult by the stubborn autoscroll function, which wasn’t a user action that could be simply undone when trying to isolate a starting point of cutting or inserting track portions. The discontinuities that disallowed seamless visual editing, as a consequence of parameterized context panes for effects and other functions, helped us reflect on which aspects of Audacity need to be reassessed and redesigned.
   
   Improved visual indication and gesture control are among two of the most critical aspects of potential redesign that our contextual inquiries seemed to call for. Visual indicators encompass both the application of effects and generations in their respective context panes as well as basic status indicators for tracks as they appear in the main project view preview. One such need we’ve identified is to streamline the approach to basic track manipulation tools, such as selections and trimming. Rather than having to cycle them with skeuomorphic, small iconed buttons, they should have mouse pointer indicators that present as the user hovers over specific track recordings’ surfaces. This is just one opportunity to minimize the unnecessarily cluttered tool and option selections surrounding the project view. Beyond ease of view, this would increase the likelihood of appropriate function use rather than best-known workarounds for common tasks. Other redesign ideas we’ve reflected on include modularly-stacked effect and generation indicators within the track header view. This would allow the user to make late-term effect tweaks after they’re been applied to tracks, which makes the entire process feel less “final” from the getgo. And in the context of parameterizing the effects, we could introduce visual adaptations of decibel magnitude, variable time, etc. with analogue graphs and particle effects rather than nonvisually-descriptive numeric fields. Furthermore, seeing color coded track portion indicators for the effects and generations would more easily indicate what was already manipulated. Another obvious redesign demand is mapping the zoom tool to the trackpad/mouse wheel. Such a simple action shouldn’t require clicking one of two small UI buttons every time. Making all of these changes in tandem with an aesthetic overhaul should begin to remedy some of the problem areas we observed among the participants’ experiences with the given tasks.
